# Map端倾斜

### 场景1-把数组展开导致mapper数据量不够

把数据select上来以后，将其中的数组进行展开，然后接一个join操作，如果每个数组中的元素有很多的话，这个时候会可能发生Map端的倾斜，这种倾斜可能不和传统的倾斜一样，卡在某个task上不动，而是所有的task都卡住了

**倾斜原因：**MR/Spark在启动MapTask的时候，是依据文件大小确定的MapTask个数，但是如果我们在Mapper里把数据撑大，如一行变十行，那这个时候之前启动的MapTask数预估就不准确了，导致可能在少量的task里处理很多的数据

**解决方式：**把这段子查询单独提取出来创建一个temporary table tmp_tb，然后后续的操作再select tmp_tb，这样可以使被撑大的数据直接落盘，而没有其他逻辑操作，等到下次select的时候，就可以重新划分maptask个数了，就可以让这些数据分布到更多的maptask中

# Reduce端数据倾斜

## Group By倾斜

### 场景1-group by count(distinct)

比如有如下sql

```sql
select city, count(distinct uid) from tb group by city
```

**存在的问题：**

1. count(distinct)：

   count(distinct uid)在spark中属于是内存操作，性能差；在mr中因为有二次排序的存在，可以做到按照city聚合，但是按照city+uid排序，使得去重操作不会浪费空间；

2. 如果city有倾斜，会导致某个task卡住

优化一：

```sql
select
	city,
	count(1) as pv
from
	(
    select
    	city,
    	uid
    from
    	tb
    group by
    	city,
 		 	uid
  ) t
group by
	city
```

这段优化解决了distinct的问题，将distinct改进成了count(1)的操作，如果开启了map端的combine，就可以在map端先进行count(1)，然后在reduce端就可以避免数据倾斜，但是如果没有开启map端combine，则需要手动加一步随机数

优化二：

```sql
select
	city,
	sum(pv) as sum_pv
from
	(
    select
      city,
      salt,
      count(1) as pv
    from
      (
        select
          city,
          uid,
          rand() as salt
        from
          tb
        group by
          city,
          uid
      ) t
    group by
      city,
      salt
  ) t
group by
	city
```

## Join倾斜

### 场景1-非法值导致倾斜

非法值太多，导致倾斜

解决方式：如果可以过滤，就直接过滤；如果不可以过滤，在join的时候加if判断置成随机数

注意：这里的非法值也可能不是表中原本的数据，而是在join的时候两个字段类型不一样导致的，如 string 和 bigint 做join的时候，hive的隐式转化会把它们都转成double做join，如果string的数据无法用double表示，那么就会是null，为了避免这种情况，可以手动把bigint转成string

hive隐式转化：

![image-20230723124255556](/Users/zhaolei/study/hive/图片/image-20230723124255556.png)

> 为什么要把string和bigint转成double呢？
> 我理解的原因是如果把bigint转成string，那么所消耗的空间可能要远大于64位，而hive作为一个通用框架，为了兼容性能，不做这种操作也是合理的，所以hive会在任务执行的时候发出警告，string和bigint类型不匹配的join可能会丢精度，因为double是

### 场景2-大表join小表倾斜

大表join小表数据倾斜

解决方式：mapjoin

### 场景3-大表join大表倾斜

大表join大表，其中一张表的数据倾斜，另一张表不倾斜

如下sql，比如在tb_process1中uid=20倾斜：

```sql
select
	t1.uid,
	name,
	grade
from 
	(
    select
    	uid,
    	name
  	from
    	tb_process1
  ) t1
  left join (
    select
    	uid,
    	grade
    from
    	tb_process2
  ) t2 on t1.uid = t2.uid
```

**解决方式1：**

把这个key单独写逻辑，采用mapjoin，然后将结果和其他的逻辑union在一起

```sql
select
	t1.uid,
	name,
	grade
from 
	(
    select
    	uid,
    	name
  	from
    	tb_process1
  	where
    	uid != 20
  ) t1
  left join (
    select
    	uid,
    	grade
    from
    	tb_process2
  	where uid != 20
  ) t2 on t1.uid = t2.uid
union all
select
	t1.uid,
	name,
	grade
from 
	(
    select
    	uid,
    	name
  	from
    	tb_process1
  	where
    	uid = 20
  ) t1
  left join (
    select
    	uid,
    	grade
    from
    	tb_process2
  	where uid = 20
  ) t2 on t1.uid = t2.uid
```

**解决方式2：**

如果小表中的数据也不算少，无法做mapjoin，那么可以把把发生倾斜的表中的数据加[0, n)的随机数后缀，然后将不倾斜的表中的数据复制n份，并且加上这个后缀，在join时候key就是原始key+随机数（这个也是spark3.0自适应机制中解决数据倾斜的思路，将倾斜key分成几份，然后将另一个表复制）

如下sql：

```sql
select
	t1.uid,
	name,
	grade
from 
	(
    select
    	uid,
    	name,
    	rand() * 1000 % 10 as salt
  	from
    	tb_process1
    where
    	uid = 20
  ) t1
  left join (
    select
    	uid,
    	grade,
    	slat
    from
    	(
        select
          uid,
          grade,
        	split(space(9), '') as salt_array
        from
          tb_process2
        where
        	uid = 20
      ) m1 lateral view posexplode(salt_array) as salt, val
  ) t2 on t1.uid = t2.uid and t1.salt = t2.salt
```

## Order by倾斜

order by是做全局排序的，为了保障全局有序，它需要将所有的数据发送到一个reduce节点上进行排序，这种很容易发生数据倾斜

### 场景1-有limit限制

一般情况下，我们很少需要对全局的数据进行排序，所以我们可以加limit的限制，如下

```sql
select
	uid,
	age
from
	tb_user
order by
	pv desc
limit
	500000
```

这样可以使得reduce不用对全部数据进行排序，而是只需要维护一个堆，输出前500000的元素即可

**存在的问题：**

如果tb_user这个表中的数据有很多，那么这一个reduce就算只取前500000需要扫描的数据也是非常多的

**解决方式：**

为了减少在最后排序过程中扫描的数据量，可以在全排序前引入一个reduce先将数据减少，然后再全排序，如下

```sql
select
	uid,
	age
from
	(
      select
        uid,
        age
      from
        (
          select
            uid,
            age,
            dense_rank() over(
              partition by
                uid % 10
              order by
                age desc
            ) rn
          from
            tb_user
        ) t
      where
        rn <= 500000
    ) t
order by
	age desc
limit
	500000
```

如果原始数据有5亿条，那么上面的sql可以将最后进入reduce的数据量编程mod * 500000条，mod是uid模的值

### 场景2-没有limit限制

如果说一定要对所有数据进行全排序，我们可以鉴戒MapReduce全排序优化的思路，具体可查看https://blog.csdn.net/stable_zl/article/details/127199163，简单来说，就是先采样探查，再分组，然后在每个组内做排序，再合并

i.对于sql来说，第一步先随机抽取100w个uid探查age的分布范围

```sql
select
	age,
	count(1) pv
from
	(
    select
    	uid,
    	age,
    	row_number() over(
        partition by
        	uid
      ) rn
    from
    	tb_user
  ) t
where
	rn <= 1000000
group by
	age
```

ii.假设我们依据这个得到了100w个uid的age的分布图，假设分成均匀的10组，然后对每个组内的数据进行排序，比如分成的组如下：

[0, 20)，[20, 25), [25, 30), [30, 35), [35, 40)，[40, 45),  [45, 50),  [50, 55), [55, 80), [80, 100)

那么在写sql的时候就可以写成

```sql
-- 这里要写成临时表，不能用with，with会导致下面多次使用的时候多次计算
create temporary table tmp_user_group_rn as 
select
	uid,
	age,
	age_group,
	row_number() over(
    partition by age_group
    order by age desc
  ) as rn
from
  (
    select
      uid,
      age,
      case	
        when age >= 0  and age < 20 then 1
        when age >= 20 and age < 25 then 2
        when age >= 25 and age < 30 then 3
        when age >= 30 and age < 35 then 4
        when age >= 35 and age < 40 then 5
        when age >= 40 and age < 45 then 6
        when age >= 45 and age < 50 then 7
        when age >= 50 and age < 55 then 8
        when age >= 55 and age < 80 then 9
        when age >= 80 and age < 100 then 10
      end as age_group
    from
      tb_user
  ) t
;
```

iii.在每个组内做排序，再合并

```sql
select
	uid,
	age,
	age_group,
	-- 组内排名 + 之前组的综合，就是当前元素在整体中的排名
	rn + before_group_rank as cur_rn
from
	(
    select
      uid,
      age,
      age_group
      rn
    from
      tmp_user_group_rn
  ) t1
  join (
    select
    	age_group,
    	-- 截止到当前组最大排名的总和，减去当前组的最大值，就是前面所有组的总和，也是当前组排名的起始点
    	group_total_rank - cur_group_max as before_group_rank
    from
    	(
        select
          age_group,
          cur_group_max,
        	-- 
          sum(cur_group_max) over (
            order by age_group
          ) as group_total_rank
        from
          (
            select
              age_group,
            	-- 当前这个组中最大的排名
              max(rn) as cur_group_max
            from
              tmp_user_group_rn
            group by
              age_group
          ) max_g
       ) group_total
  ) t2
```

